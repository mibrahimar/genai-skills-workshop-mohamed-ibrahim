{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "QZInenYYZ2D8",
      "metadata": {
        "id": "QZInenYYZ2D8"
      },
      "source": [
        "# Challenge two: Programming a RAG system in BigQuery\n",
        "Goal: Demonstrate your ability to program a RAG system that uses BigQuery to generate embeddings and perform a vector search."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gzL4gqY4rIg1",
      "metadata": {
        "id": "gzL4gqY4rIg1"
      },
      "source": [
        "### Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5P-OHgrfrKTn",
      "metadata": {
        "id": "5P-OHgrfrKTn"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-google-genai langchain-google-vertexai langchain-google-community langchain-core --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y0kmIfkXcrR9",
      "metadata": {
        "id": "y0kmIfkXcrR9"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y6ceNvS2BZwGuCw8mVsrBN6y",
      "metadata": {
        "id": "Y6ceNvS2BZwGuCw8mVsrBN6y",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AWEbZvcXjeGa",
      "metadata": {
        "id": "AWEbZvcXjeGa"
      },
      "source": [
        "### Setup variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scD1oMFIjgC-",
      "metadata": {
        "id": "scD1oMFIjgC-"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID='qwiklabs-gcp-03-7a8bdf6e2e2c'\n",
        "LOCATION='us'\n",
        "DATASET = \"AuroraBay\"\n",
        "TABLE = \"faqs\"\n",
        "TABLE_EMBEDDED = \"faqs_embedded\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HZrZzkR1c3SZ",
      "metadata": {
        "id": "HZrZzkR1c3SZ"
      },
      "outputs": [],
      "source": [
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sX6n5l_pjD8z",
      "metadata": {
        "id": "sX6n5l_pjD8z"
      },
      "source": [
        "### Create a new dataset in BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mN0eqmDtdHVB",
      "metadata": {
        "id": "mN0eqmDtdHVB"
      },
      "outputs": [],
      "source": [
        "# Create dataset\n",
        "dataset_id = \"{}.{}\".format(client.project, DATASET)\n",
        "\n",
        "# Construct a full Dataset object to send to the API.\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "\n",
        "# Specify the geographic location where the dataset should reside.\n",
        "dataset.location = \"US\"\n",
        "\n",
        "dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
        "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xw4cWwvNjGfb",
      "metadata": {
        "id": "xw4cWwvNjGfb"
      },
      "source": [
        "### Create a new table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cYoOFlAPdbG8",
      "metadata": {
        "id": "cYoOFlAPdbG8"
      },
      "outputs": [],
      "source": [
        "# Create table\n",
        "table_id = \"{}.{}.{}\".format(client.project, dataset.dataset_id, TABLE)\n",
        "\n",
        "table = bigquery.Table(table_id)\n",
        "table = client.create_table(table)  # API request\n",
        "\n",
        "print(f\"Created {table_id}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xqdisogzjPtO",
      "metadata": {
        "id": "xqdisogzjPtO"
      },
      "source": [
        "### Load CSV into table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jhAh5mvNd4EY",
      "metadata": {
        "id": "jhAh5mvNd4EY"
      },
      "outputs": [],
      "source": [
        "# Load data from CSV\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=[\n",
        "        bigquery.SchemaField(\"question\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"answer\", \"STRING\"),\n",
        "    ],\n",
        "    skip_leading_rows=1,\n",
        "    # The source format defaults to CSV, so the line below is optional.\n",
        "    source_format=bigquery.SourceFormat.CSV,\n",
        ")\n",
        "uri = \"gs://labs.roitraining.com/aurora-bay-faqs/aurora-bay-faqs.csv\"\n",
        "\n",
        "load_job = client.load_table_from_uri(\n",
        "    uri, table_id, job_config=job_config\n",
        ")  # Make an API request.\n",
        "\n",
        "load_job.result()  # Waits for the job to complete.\n",
        "\n",
        "destination_table = client.get_table(table_id)  # Make an API request.\n",
        "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6ntsPS3jTb_",
      "metadata": {
        "id": "d6ntsPS3jTb_"
      },
      "source": [
        "### Create a Cloud resource connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HiVEQjqTf2Zp",
      "metadata": {
        "id": "HiVEQjqTf2Zp"
      },
      "outputs": [],
      "source": [
        "!bq mk --connection --connection_type=CLOUD_RESOURCE --location=us --project_id={PROJECT_ID} \"embedding_conn\"\n",
        "!bq show --location=us --connection --project_id={PROJECT_ID} \"embedding_conn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rti3JHLXj0sD",
      "metadata": {
        "id": "Rti3JHLXj0sD"
      },
      "outputs": [],
      "source": [
        "# Update you service acccount here\n",
        "connection_service_account = \"bqcx-569779670169-huh6@gcp-sa-bigquery-condel.iam.gserviceaccount.com\" # @param {\"type\": \"string\"}\n",
        "connection_member = f\"serviceAccount:{connection_service_account}\"\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member={connection_member} --role='roles/aiplatform.user' --condition=None --quiet\n",
        "# !gcloud projects add-iam-policy-binding {PROJECT_ID} --member={connection_member} --role='roles/bigquery.dataowner' --condition=None --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OPakJ82Bkb34",
      "metadata": {
        "id": "OPakJ82Bkb34"
      },
      "source": [
        "### Create embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4VP5EY3vkcUu",
      "metadata": {
        "id": "4VP5EY3vkcUu"
      },
      "outputs": [],
      "source": [
        "query = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `AuroraBay.Embeddings`\n",
        "REMOTE WITH CONNECTION `us.embedding_conn` OPTIONS (ENDPOINT = 'text-embedding-005');\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)  # API request\n",
        "query_job.result()  # Waits for the query to complete\n",
        "\n",
        "print(\"Embeddings table created successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fmgQXYD0le_9",
      "metadata": {
        "id": "fmgQXYD0le_9"
      },
      "source": [
        "### Generate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dYqDz9gjlgQ3",
      "metadata": {
        "id": "dYqDz9gjlgQ3"
      },
      "outputs": [],
      "source": [
        "query = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `AuroraBay.faqs_embedded` AS SELECT *\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `AuroraBay.Embeddings`,\n",
        "(SELECT CONCAT(question, ' ', answer) content FROM `AuroraBay.faqs`)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "query_job = client.query(query)  # API request\n",
        "query_job.result()  # Waits for the query to complete\n",
        "\n",
        "print(\"Embeddings generated successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Wy8GwhB9su8H",
      "metadata": {
        "id": "Wy8GwhB9su8H"
      },
      "source": [
        "## Langchain setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2H8wCg96rg1u",
      "metadata": {
        "id": "2H8wCg96rg1u"
      },
      "source": [
        "### Create an embedding class instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Peimwg1hry7m",
      "metadata": {
        "id": "Peimwg1hry7m"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "\n",
        "embedding = VertexAIEmbeddings(\n",
        "    model_name=\"text-embedding-005\", project=PROJECT_ID\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ipihLx7dvz6M",
      "metadata": {
        "id": "ipihLx7dvz6M"
      },
      "source": [
        "### Initialize BigQueryVectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tIQ2UN1av0-V",
      "metadata": {
        "id": "tIQ2UN1av0-V"
      },
      "outputs": [],
      "source": [
        "from langchain_google_community import BigQueryVectorStore\n",
        "\n",
        "store = BigQueryVectorStore(\n",
        "    project_id=PROJECT_ID,\n",
        "    dataset_name=DATASET,\n",
        "    table_name=TABLE_EMBEDDED,\n",
        "    location=LOCATION,\n",
        "    embedding=embedding,\n",
        "    embedding_field=\"ml_generate_embedding_result\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q7q_Ly5_s1Ve",
      "metadata": {
        "id": "q7q_Ly5_s1Ve"
      },
      "source": [
        "### Compose a LangChain Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xdmcl5ATtFE_",
      "metadata": {
        "id": "Xdmcl5ATtFE_"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "# See full prompt at https://smith.langchain.com/hub/rlm/rag-prompt\n",
        "prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
        "llm = VertexAI(model_name=\"gemini-2.0-flash\")\n",
        "\n",
        "qa_chain = (\n",
        "    {\n",
        "        \"context\": store.as_retriever(),\n",
        "        \"input\": RunnablePassthrough(),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gg5kJvhMvEXM",
      "metadata": {
        "id": "Gg5kJvhMvEXM"
      },
      "outputs": [],
      "source": [
        "qa_chain.invoke(\"what is 1 + 1?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a43a4cb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chat loop\n",
        "while True:\n",
        "  user_input = input(\"You: \")\n",
        "  if user_input.lower().strip() in ['exit', 'quit']:\n",
        "        print(\"👋 Bye!\")\n",
        "        break\n",
        "  print(\"Bot:\")\n",
        "  print(qa_chain.invoke(user_input))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "student-04-6610032ef201 (Jun 16, 2025, 11:52:24 AM)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
